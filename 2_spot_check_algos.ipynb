{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0XMzfB5_EtE"
   },
   "source": [
    "# Sentiment analysis of movie (IMDB) reviews \n",
    "\n",
    "using dataset provided by the ACL 2011 paper, see http://ai.stanford.edu/~amaas/data/sentiment/.\n",
    "\n",
    "Dataset can be downloaded separately from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz, but wont be necessary as the download process has been embedded in the notebook and source file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents<a class=\"anchor\" id=\"table\"></a>\n",
    "* [Data exploration](#data_e)\n",
    "* [Modelling](#model)\n",
    "    * [Logistic Regression](#logis)\n",
    "        * [Logistic Regression with bag of word](#logis_bag)\n",
    "        * [Logistic Regression with TFIDF](#logis_tfidf)\n",
    "        * [Logistic Regress model using TfidfVectorizer and different values for C hyperparameter](#logis_tfidf_hyp)\n",
    "        * [Logistic Regression with bag of word with Scikit-learn](#logis_bag_scikit)\n",
    "    * [Random Forest](#randfor)\n",
    "        * [Random Forest with bag of word](#rand_for_bag)\n",
    "        * [Random Forest with TFIDF](#rand_for_tfidf)\n",
    "    * [Display scores for all trained models](#disp_sco)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "CML_IG6z-iwM",
    "outputId": "d9301f36-c1cf-4b3f-e639-a731880ed036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jeremie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# uncomment these for Google collab, will have already been installed in local environment \n",
    "# if 'pip install -r requirements.txt' has been run\n",
    "#!pip install nltk\n",
    "#!pip install --upgrade gensim\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "\n",
    "\n",
    "import glob\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FJiWamI00hBp",
    "outputId": "e3c105d5-037f-4521-b8e1-a83cb7a5edeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory exists, taking no action\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import tarfile\n",
    "\n",
    "# By checking if the directory exists first, we allow people to delete the tarfile without the notebook re-downloading it\n",
    "if os.path.isdir('aclImdb'):\n",
    "    print(\"Dataset directory exists, taking no action\")\n",
    "else:    \n",
    "    if not os.path.isfile('aclImdb_v1.tar.gz'):\n",
    "        print(\"Downloading dataset\")\n",
    "        #!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "        wget.download('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n",
    "    else:\n",
    "        print(\"Dataset already downloaded\")\n",
    "    \n",
    "    print(\"Unpacking dataset\")\n",
    "    #!tar -xf aclImdb_v1.tar.gz \n",
    "    tar = tarfile.open(\"aclImdb_v1.tar.gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    print(\"Dataset unpacked in aclImdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook configuration\n",
    "SAMPLE_SIZE=12500\n",
    "# SAMPLE_SIZE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcTVSZK-i07N"
   },
   "outputs": [],
   "source": [
    "SLICE = int(SAMPLE_SIZE / 2)\n",
    "positive_file_list = glob.glob(os.path.join('aclImdb/train/pos', \"*.txt\"))\n",
    "positive_sample_file_list = positive_file_list[:SLICE]\n",
    "\n",
    "negative_file_list = glob.glob(os.path.join('aclImdb/train/neg', \"*.txt\"))\n",
    "negative_sample_file_list = negative_file_list[:SLICE]\n",
    "\n",
    "import re\n",
    "\n",
    "# load doc into memory\n",
    "# regex to clean markup elements \n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r', encoding='utf8')\n",
    "    # read all text\n",
    "    text = re.sub('<[^>]*>', ' ', file.read())\n",
    "    #text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vMYBkcdIB9uc"
   },
   "source": [
    "<a href='#table'>Back</a>\n",
    "# Data exploration<a class=\"anchor\" id=\"data_e\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cz5eJi7AGSqR"
   },
   "outputs": [],
   "source": [
    "positive_strings = [load_doc(x) for x in positive_sample_file_list]\n",
    "# print('\\n Positive reviews \\n ',positive_strings[:5])\n",
    "\n",
    "negative_strings = [load_doc(x) for x in negative_sample_file_list]\n",
    "#print('\\n Negative reviews \\n ', negative_strings[:5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0WiHTr7I4CN"
   },
   "outputs": [],
   "source": [
    "positive_tokenized = [word_tokenize(s) for s in positive_strings]\n",
    "#print('\\n Positive tokenized 1 \\n {} \\n\\n Positive tokenized 2 \\n {}'. format(positive_tokenized[1], positive_tokenized[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDP-eqAGIq5R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Negative tokenized 1 \n",
      " ['The', 'reason', 'the', 'DVD', 'releases', 'of', 'this', 'film', 'are', 'in', 'black', 'and', 'white', 'is', 'because', 'nobody', 'can', 'get', 'their', 'hands', 'on', 'a', 'color', 'print', 'of', 'this', 'public', 'domain', 'film', ',', 'a', 'modest', 'sea', 'story', 'at', 'best', '.', 'Distributed', 'for', 'television', 'thru', 'Allied', 'Artists', ',', 'DVD', \"'s\", '(', 'or', 'VHS', ')', 'on', 'the', 'market', 'at', 'this', 'time', 'for', 'this', 'title', 'are', 'all', 'coming', 'from', 'the', 'same', '16MM', 'television', 'print', '.', 'Films', 'distributed', 'for', 'television', 'prior', 'to', '1963', 'were', 'often', 'distributed', 'in', 'b/w', 'prints', ',', 'because', 'the', 'bulk', 'of', 'viewers', 'did', 'not', 'have', 'color', 'sets', 'anyway', '.', 'Striking', 'b/w', 'prints', 'for', 'television', 'was', 'also', 'cheaper', ',', 'as', 'it', 'often', 'involved', 'quite', 'a', 'few', 'prints', 'to', 'cover', 'all', 'stations', 'running', 'a', 'film', 'on', 'a', 'syndicated', 'basis', '.'] \n",
      "\n",
      "  Negative tokenized 2 \n",
      " ['I', 'wanted', 'to', 'like', 'Magnolia', '.', 'The', 'plot', 'reminded', 'me', 'of', 'Grand', 'Canyon', '(', 'which', 'I', 'liked', ')', '.', '4', 'different', 'lives/stories', 'that', 'come', 'together', 'at', 'the', 'end', 'but', 'Magnolia', 'took', 'a', 'wrong', 'turn', 'halfway', 'through', 'the', 'movie', 'and', 'I', 'was', 'lost', '.', 'I', 'almost', 'turned', 'it', 'off', 'right', 'then', 'and', 'there', 'but', 'I', 'felt', 'I', 'should', 'hang', 'in', 'there', 'until', 'the', 'end', ',', 'little', 'did', 'I', 'know', 'it', 'would', 'be', 'another', 'torturous', '1', '1/2', 'hours', '.', 'Thank', 'god', 'I', 'rented', 'instead', 'of', 'seeing', 'it', 'in', 'the', 'theatre', '.', 'I', 'almost', 'screamed', 'out', 'in', 'frustration', 'after', '2', 'hours', '.', 'The', 'biggest', 'kick', 'in', 'the', 'pants', 'was', 'the', 'ending', 'frog', 'scene', '.', 'My', 'DVD', 'player', 'still', 'has', \"n't\", 'forgiven', 'me', 'and', 'I', 'do', \"n't\", 'blame', 'it', 'one', 'bit', '.', 'It', 'was', 'a', 'unique', 'movie', ',', 'but', 'a', 'bad', ',', 'boring', ',', 'and', 'pointless', 'movie', '.']\n"
     ]
    }
   ],
   "source": [
    "negative_tokenized = [word_tokenize(s) for s in negative_strings]\n",
    "print('\\n Negative tokenized 1 \\n {} \\n\\n  Negative tokenized 2 \\n {}'. format(negative_tokenized[1], negative_tokenized[2]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "6bgN1KJRMPpq",
    "outputId": "aa69f5b0-246f-4805-bc36-9944c1f36b3a"
   },
   "source": [
    "# load doc into memory\n",
    "with open('aclImdb/imdb.vocab', encoding='utf8') as f:\n",
    "    #content = f.readlines()\n",
    "    universe_vocabulary = [x.strip() for x in f.readlines()]\n",
    "\n",
    "print(\"Word count across all reviews (before stripping tokens):\", sum([len(token) for token in positive_tokenized]))\n",
    "\n",
    "#Checking the not alphanumeric characters in vocabulary\n",
    "non_alphanumeric_set = set()\n",
    "for word in universe_vocabulary:\n",
    "    non_alphanumeric_set |= set(re.findall('\\W', word))\n",
    "print('Non alphanumeric characters found in universe vocabulary', non_alphanumeric_set)\n",
    "\n",
    "\n",
    "stripped_positive_tokenized = []\n",
    "for tokens in positive_tokenized:\n",
    "  stripped_positive_tokenized.append([token.lower() for token in tokens if token.lower() in universe_vocabulary])\n",
    "\n",
    "print(\"Word count across all reviews (after stripping tokens):\", sum([len(token) for token in stripped_positive_tokenized]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "DSFWrZInMueS",
    "outputId": "4ae1eab3-3e09-41a5-9778-22aa72ce5cdb"
   },
   "source": [
    "print(\"Word count across all reviews (before stripping tokens):\", sum([len(token) for token in positive_tokenized]))\n",
    "stripped_negative_tokenized = []\n",
    "for tokens in negative_tokenized:\n",
    "  stripped_negative_tokenized.append([token.lower() for token in tokens if token.lower() in universe_vocabulary])\n",
    "\n",
    "print(\"Word count across all reviews (after stripping tokens):\", sum([len(token) for token in stripped_negative_tokenized]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnu21deYOkDE"
   },
   "source": [
    "<a href='#table'>Back</a>\n",
    "# Modelling <a class=\"anchor\" id=\"model\"></a> \n",
    "\n",
    "We have decided to do the use the below models and vectorisation techniques to test our their accuracy / score, the idea is to use a one model and one vectorization technique and plot a score.\n",
    "\n",
    "**Vectorisation techniques**\n",
    "- Bag of Words\n",
    "- TFIDF (weighted bag of words) http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "- mapping words to plain integers\n",
    "- mapping words to embedding vectors\n",
    "\n",
    "\n",
    "**Simple models**\n",
    "\n",
    "- Logistic Regression\n",
    "- Random Forst\n",
    "- LSTM\n",
    "- GRU\n",
    "- CNN\n",
    "\n",
    "**Embeddings to try**\n",
    "- Word2Vec\n",
    "- FastText\n",
    "- Glove\n",
    "\n",
    "**APIs we used**\n",
    "- Introducing Pipeline: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "- Introducing cross_val_score http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[[\"title\",\"train_acc\",\"test_acc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGh1Vqp3XNJI"
   },
   "source": [
    "## Logistic Regression <a class=\"anchor\" id=\"logis\"></a> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "lfr3bXOgXNJJ",
    "outputId": "cc06dd0d-e886-4090-c972-cd05520adaf3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_positives = pd.DataFrame({'reviews':[load_doc(x) for x in positive_sample_file_list], 'sentiment': np.ones(SLICE)})\n",
    "df_negatives = pd.DataFrame({'reviews':[load_doc(x) for x in negative_sample_file_list], 'sentiment': np.zeros(SLICE)})\n",
    "\n",
    "# print(\"Positive review: {} \\n\".format(df_positives['reviews'][1][0:200]))\n",
    "# print(\"Negative review: {}\".format(df_negatives['reviews'][1][0:200]))\n",
    "\n",
    "df = pd.concat([df_positives, df_negatives], ignore_index=True)\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-BsaFCwXNJQ"
   },
   "source": [
    "### Logistic Regress model using Bag of Words vectorisation technique<a class=\"anchor\" id=\"logis_bag\"></a> \n",
    "WONT WORK ON LARGE DATASET"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "XtV8N-0zXNJ4",
    "outputId": "d76d5eea-9796-4eb7-a158-1f6ccdcd3db9"
   },
   "source": [
    "CountVec = CountVectorizer()\n",
    "# Creating the BoW with the set of all the documents and transforming the documents in feature vectors\n",
    "bag_of_words = CountVec.fit_transform(df['reviews'])\n",
    "\n",
    "# Lets get our training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words.toarray(), df['sentiment'].values, test_size=0.25)\n",
    "\n",
    "model=LogisticRegression(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "train_acc=model.score(X_train, y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model.score(X_test, y_test)\n",
    "print('Test accuracy {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "report_df = pd.DataFrame({\n",
    "        \"acc_categorical_accuracy\": train_acc, \n",
    "        \"loss  val_acc\": None,  \n",
    "        \"val_categorical_accuracy\":test_acc,\n",
    "        \"val_loss\": None, \n",
    "        \"title\": \"Logistic Regress model using Bag of Words Vectorisation Technique\",\n",
    "        \"sample_size\": SAMPLE_SIZE, \n",
    "        \"nb_epochs\":None\n",
    "            },index=[0])\n",
    "\n",
    "\n",
    "print(report_df)\n",
    "# df.to_csv(path_or_buf=df.iloc[0].title+\".csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "# # Trying with cross_val_score\n",
    "lr = LogisticRegression()\n",
    "k_folds = 10\n",
    "X_train_CV = CountVec.fit_transform(X_train)\n",
    "type(X_train_CV)\n",
    "print('Train accuracy list {} '.format(cross_val_score(lr, X_train_CV, y_train, cv= k_folds))) \n",
    "print('Train accuracy mean {} '.format(cross_val_score(lr, X_train_CV, y_train, cv= k_folds).mean()))\n",
    "\n",
    "scores.append([\"Logistic Reg with BoW\",train_acc,test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeUltp6gXNJd"
   },
   "source": [
    "### Logistic Regress model using TfidfVectorizer vectorisation technique<a class=\"anchor\" id=\"logis_tfidf\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12500x56592 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1717511 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVec = CountVectorizer()\n",
    "# Creating the BoW with the set of all the documents and transforming the documents in feature vectors\n",
    "bag_of_words=CountVec.fit_transform(df['reviews'])\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12500x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1581753 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents='ascii', lowercase=True, preprocessor=None,max_features=10000)\n",
    "reviews_tfidf=tfidf.fit_transform(df['reviews'])\n",
    "reviews_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lets get our training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_tfidf, df['sentiment'].values, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9303466666666667\n",
      "Test accuracy 0.87648\n"
     ]
    }
   ],
   "source": [
    "time_beginning_of_training = time.time()\n",
    "model=LogisticRegression(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "train_acc=model.score(X_train, y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=model.score(X_test, y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "time_end_of_training = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19634270668029785"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_end_of_training-time_beginning_of_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       title  sample_size       acc  val_acc\n",
      "0  Logistic Regression with Tfidf vectorizer        12500  0.926613  0.88256\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "df.reset_index(inplace=True)\n",
    "df[\"title\"]=[\"Logistic Regression with Tfidf vectorizer\"]\n",
    "df[\"sample_size\"]=[SAMPLE_SIZE]\n",
    "df[\"acc\"]=train_acc\n",
    "df[\"val_acc\"]=test_acc\n",
    "df.drop(labels=\"index\",axis=1,inplace=True)\n",
    "print(df)\n",
    "df.to_csv(path_or_buf=\"reports/\"+df.iloc[0].title+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9375, 10000)\n",
      "(3125, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2lMqoGKXNJl"
   },
   "source": [
    "### Logistic Regress model using TfidfVectorizer and different values for C hyperparameter<a class=\"anchor\" id=\"logis_tfidf_hyp\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "zZZOXbA4XNJm",
    "outputId": "518f52ab-2ccd-4bca-9105-5fdcf5c797ef"
   },
   "outputs": [],
   "source": [
    "C_values = np.arange(1,2,0.1)\n",
    "results = []\n",
    "\n",
    "for value in C_values:   \n",
    "    lr_tfidf = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0, C=value))])\n",
    "    lr_tfidf.fit(X_train, y_train)\n",
    "    train_score = lr_tfidf.score(X_train, y_train)\n",
    "    score = lr_tfidf.score(X_test, y_test)\n",
    "    print('C_value {} Test Score {} Train_score {}'.format(value, score, train_score))\n",
    "    results.append(score)\n",
    "\n",
    "time_end_of_notebook = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "colab_type": "code",
    "id": "6siRLHQU79F7",
    "outputId": "dbc21ee2-1066-4b68-c8a0-ad47ca57f4b4"
   },
   "outputs": [],
   "source": [
    "table_models_vectorization = pd.DataFrame(\n",
    "     {'Models':                   [\"Logistic Regression\", \"Logistic Regression\", \"Logistic Regression\"], \n",
    "      'Vectorisation techniques': [\"Bag of Words\",        \"Word2Vec\", \"TFIDF\"], \n",
    "      'Score':                    [score,                 \"Pending\", lr_tfidf.score(X_train, y_train) ]},\n",
    "    columns=['Models','Vectorisation techniques','Score']\n",
    ")\n",
    "print(\"Sample size:\", SAMPLE_SIZE)\n",
    "\n",
    "duration = time_end_of_notebook - time_beginning_of_notebook\n",
    "\n",
    "print(\"Full notebook execution duration:\", duration, \"seconds\")\n",
    "print(\"Full notebook execution duration:\", duration / 60, \"minutes\")\n",
    "\n",
    "table_models_vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-BsaFCwXNJQ"
   },
   "source": [
    "### Logistic Regress model using Bag of Words with scikit-learn<a class=\"anchor\" id=\"logis_bag_scikit\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-28yfXCkgTe"
   },
   "source": [
    "**The below two code blocks replaces the original/inital BoW implementation using Scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "XtV8N-0zXNJ4",
    "outputId": "d76d5eea-9796-4eb7-a158-1f6ccdcd3db9"
   },
   "outputs": [],
   "source": [
    "CountVec = CountVectorizer()\n",
    "# Creating the BoW with the set of all the documents and transforming the documents in feature vectors\n",
    "bag_of_words = CountVec.fit_transform(df['reviews'])\n",
    "\n",
    "print(type(bag_of_words))\n",
    "print('\\n Number of raws {} (documents) -- Number of columns {} (vocabulary) \\n'.format(bag_of_words.shape[0], bag_of_words.shape[1]))\n",
    "\n",
    "# https://machinelearningmastery.com/sparse-matrices-for-machine-learning/\n",
    "# This is a sparse matrix \n",
    "print('\\n Type of bag_of_words {} \\n'.format(type(bag_of_words)))\n",
    "sparsity = 1.0 - bag_of_words.nnz / (bag_of_words.shape[0] * bag_of_words.shape[1])\n",
    "print('\\n Sparsity {} \\n'.format(sparsity))\n",
    "\n",
    "# This is a  \n",
    "print('\\n Type of bag_of_words.toarray {} \\n'.format(type(bag_of_words.toarray())))\n",
    "\n",
    "# In CountVec we have the vocabulary as an attribute\n",
    "print('\\n Type of CountVec.vocabulary {} \\n'.format(type(CountVec.vocabulary_)))\n",
    "print('A sample of CountVec.vocabulary_ {}'.format([(k, v) for k, v in CountVec.vocabulary_.items() if v < 1000][0:5]))\n",
    "\n",
    "# In bag_of_words we have the vector features representing each single document \n",
    "print('\\n Type of bag_of_words.toarray() {} \\n')\n",
    "print('\\n First feature vector, representing the first document \\n', bag_of_words[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c6A2pKzOmxzT"
   },
   "outputs": [],
   "source": [
    "# Lets get our training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words.toarray(), df['sentiment'].values, test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "pqbPNSGUg4Rj",
    "outputId": "b5976680-a41d-4736-99b7-e5e17ce473f2"
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Using score function: {}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "results = [(predicted, actual) for predicted, actual in zip(clf.predict(X_test),  y_test) \n",
    "           if  predicted == actual]\n",
    "\n",
    "print('Percentage of correct predicted values: {}'.format(len(results)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0YIRBaroMeM"
   },
   "source": [
    "## RandomForestClassifer<a class=\"anchor\" id=\"rand_for\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BM0YI71dnpZE"
   },
   "source": [
    "### RandomForestClassifer with bag of words<a class=\"anchor\" id=\"rand_for_bag\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "nMUUsMLkkyLO",
    "outputId": "8b2096de-ded8-4e02-b75a-046b1861f529"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "train_acc=clf.score(X_train, y_train)\n",
    "test_acc=clf.score(X_test, y_test)\n",
    "print('Using score function: {}'.format(test_acc))\n",
    "\n",
    "\n",
    "results = [(predicted, actual) for predicted, actual in zip(clf.predict(X_test),  y_test) \n",
    "           if  predicted == actual]\n",
    "\n",
    "print('Percentage of correct predicted values: {}'.format(len(results)/len(y_test)))\n",
    "\n",
    "scores.append([\"Random Forest with BoW\",train_acc,test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BM0YI71dnpZE"
   },
   "source": [
    "### RandomForestClassifer with TFIDF (Pipeline)<a class=\"anchor\" id=\"rand_for_tfidf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "HNluLDB4nayq",
    "outputId": "2ee1d453-891e-45d9-ad20-2d8bd81c3853"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviews'], df['sentiment'], test_size=0.25)\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf), ('clf', RandomForestClassifier(n_estimators=1000))])\n",
    "lr_tfidf.fit(X_train, y_train)\n",
    "train_acc=lr_tfidf.score(X_train, y_train)\n",
    "print('Train accuracy {}'.format(train_acc))\n",
    "test_acc=lr_tfidf.score(X_test, y_test)\n",
    "print('Test accuracy {}'.format(test_acc))\n",
    "\n",
    "# Trying with cross_val_score\n",
    "lr = LogisticRegression()\n",
    "k_folds = 10\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "print('Train accuracy list {} '.format(cross_val_score(lr, X_train_tfidf, y_train, cv= k_folds))) \n",
    "print('Train accuracy mean {} '.format(cross_val_score(lr, X_train_tfidf, y_train, cv= k_folds).mean()))\n",
    "\n",
    "scores.append([\"Random Forest with Tfidf\",train_acc,test_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BM0YI71dnpZE"
   },
   "source": [
    "## Display scores for all trained models<a class=\"anchor\" id=\"disp_sco\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores_df=pd.DataFrame(data=scores[1:],columns=scores[0])\n",
    "\n",
    "print(scores_df)\n",
    "scores_df.train_acc=scores_df.train_acc.astype(float)\n",
    "scores_df.test_acc=scores_df.test_acc.astype(float)\n",
    "plt.rcParams[\"figure.figsize\"] = [24,5]\n",
    "\n",
    "ax=scores_df.plot(y=[\"train_acc\",\"test_acc\"])\n",
    "ax.set_xticks(scores_df.index);\n",
    "ax.set_xticklabels(scores_df.title);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes Jeremie 22/11: if you run the algorithms multiple times, you might get different values for accuracies, and random forest is not necessarily consistently better.\n",
    "\n",
    "Might be worth reevaluating all algorithms using k-folds cross validation technique to have hopefully more consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment analysis of movies (IMDB).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
